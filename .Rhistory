ggplot(A, aes(x = x, y = V1)) + geom_line() +
geom_line(aes(x = y, y = V11)) +
geom_line(aes(x = x, y = V6)) +
geom_line(aes(x = y, y = V16))
ggplot(A, aes(x = x, y = V1)) + geom_line() +
geom_line(aes(x = y, y = V11)) +
geom_line(aes(x = x, y = V6)) +
geom_line(aes(x = y, y = V16)) +
geom_blank()
a = ggplot(A, aes(x = x, y = V1)) + geom_line()
b = ggplot(A) + geom_line(aes(x = y, y = V11))
d = ggplot(A) + geom_line(aes(x = x, y = V6))
e = ggplot(A) + geom_line(aes(x = y, y = V16))
gridExtra::grid.arrange(a, b, d, e, nrow = 2)
# number of Samples nn = 3, 5, 10, 25
# Identical Sample Size n_i = 3, 5, 10, 15, 25, 50, 100, 1000
# Identical Cluster Size m_ij = 3, 5, 10, 15, 20, 25, 40
# One Large, One Small Cluster m_ij = 10, 15, 20, 25; m_ik = 3; m_ih = 40
# One Large, One Small Sample n_i = 10, 15, 25, 50; n_j = 3; n_k = 150
# Identical Cluster Size m_ij = 3, 5, 10, 15, 20, 25, 40
# One Large, One Small Cluster m_ij = 10, 15, 20, 25; m_ik = 3; m_ih = 40
# number of samples
nn = c(3, 5, 10)
each_s = c(F, T)
both_s = c(F, T)
# Identical Sample Sizes --------------------------------------------------
n_i = c(3, 5, 10, 15, 20, 25, 50, 100)
# Identical Cluster Size
m_ij = c(3, 5, 10, 15, 20, 25, 40)
nm_1 = expand.grid(nn, n_i, m_ij)
nm_1$each_s = F
nm_1$both_s = F
nm_1$identical_s = T
nm_1$identical_c = T
nm_1$grp = 1
colnames(nm_1)[1:3] = c("nn", "n_i", "m_ij")
# Large/Small Cluster
m_ij = c(10, 15, 20, 25)
nm_2 = expand.grid(nn, n_i, m_ij, each_s, both_s)
nm_2$identical_s = T
nm_2$identical_c = F
colnames(nm_2)[1:5] = c("nn", "n_i", "m_ij", "each_s", "both_s")
# Remove invalid condition
nm_2 = nm_2[-which(which(nm_2$each_s == T) %in% which(nm_2$both_s == F)),]
nm_2$grp = 2
# Large/Small Sample Size -------------------------------------------------
n_i = c(10, 15, 25, 50)
# Identical Cluster Size
m_ij = c(3, 5, 10, 15, 20, 25, 40)
nm_3 = expand.grid(nn, n_i, m_ij)
nm_3$each_s = F
nm_3$both_s = F
nm_3$identical_s = F
nm_3$identical_c = T
nm_3$grp = 3
colnames(nm_3)[1:3] = c("nn", "n_i", "m_ij")
# Large/Small Cluster
m_ij = c(10, 15, 20, 25)
nm_4 = expand.grid(nn, n_i, m_ij, each_s, both_s)
nm_4$identical_s = F
nm_4$identical_c = F
colnames(nm_4)[1:5] = c("nn", "n_i", "m_ij", "each_s", "both_s")
nm_4 = nm_4[-which(which(nm_4$each_s == T) %in% which(nm_4$both_s == F)),]
nm_4$grp = 4
# Bind --------------------------------------------------------------------
samples = rbind(nm_1, nm_2, nm_3, nm_4)
sets = samples[3]
sets = samples[3,]
sets$nn
samples
head(samples)
settings = samples
settings$rho  = rho
settings$wald = 0
settings$anv  = 0
settings$maxt = 0
which(colnames(settings) == c("wald", "anv", "maxt"))
which(colnames(settings) %in% c("wald", "anv", "maxt"))
settings[,9:11]
which(colnames(settings) %in% c("wald", "anv", "maxt"))
AB = list()
names(AB)
AB[[1]] = rnorm(100)
names(AB)
names(AB) = "a"
names(AB)
AB
AB$a
rbinom(10, 5, 0.5)
a = rbinom(10, 5, 0.5)
mean(a)
a = rpois(10, 5)
mean(a)
a
a = c(rpois(9, 5), 12)
mean(a)
a
a = c(rpois(9, 5), 17)
mean(a)
a
sort(a)
7 * 24
ind = c(1:10)
x = c(3, 2, 4, 8, 3, 7, 5, 6, 3, 17)
ord = order(x)
ord
x_n = x[ord]
ind_n = ind[ord]
x_n
ind_n = ind[ord]
ind_n
median(x)
median(x)
quantile(x, probs = c(0.25, 0.75))
10 * 0.75
x_n[8]
x_n
sum(x_n)
mean(x)
var_tab = data.frame("(i)" = ind, "i" = ind_n, "x_(i)" = x_n, "cent" = x_n - mean(x), "cent_sq" = (x_n - mean(x))^2)
var_tab
sum(var_tab$cent_sq)
sum(var_tab$cent_sq) / 9
sqrt(sum(var_tab$cent_sq) / 9)
mean(x)
median(x)
devtools::install_github("spruenke/rankCluster")
library(rankCluster)
setwd("D:/Dropbox/Charite/GARGAR")
dat = read.csv("GARGAR.csv")
dat = read.csv2("GARGAR.csv")
View(dat)
?read.table
dat = read.delim("GARGAR.csv")
View(dat)
colnames(dat)
head(dat[,79:83])
setwd("D:/Dropbox/Studium/M.Sc. Statistics/Semester IV/Thesis/Code/MasterThesis")
rm(list = ls())
# Preparation -------------------------------------------------------------
if(!("MASS" %in% installed.packages())) install.packages("MASS", dependencies = T)
if(!("mvtnorm" %in% installed.packages())) install.packages("mvtnorm", dependencies = T)
if(!("copula" %in% installed.packages())) install.packages("copula", dependencies = T)
if(!("multcomp" %in% installed.packages())) install.packages("multcomp", dependencies = T)
if(!("Rcpp" %in% installed.packages())) install.packages("Rcpp", dependencies = T)
if(!("RcppArmadillo" %in% installed.packages())) install.packages("RcppArmadillo", dependencies = T)
if(!("doParallel" %in% installed.packages())) install.packages("doParallel", dependencies = T)
if(!("foreach" %in% installed.packages())) install.packages("foreach")
if(!("rankCluster" %in% installed.packages())) devtools::install_github("spruenke/rankCluster")
#source("util.R")
#source("dat_gen.R")
#source("stats.R")
source("settings.R")
nsim  = 100 # Number of Simulation Runs
dists = c("norm", "pois", "beta", "binom")
param_list = list(list(mean = 0, sd = 1), list(lambda = 3), list(shape1 = 2, shape2 = 5), list(size = 1, prob = 0.5))
start_time = Sys.time()
for(u in 1:length(dists)){
sim_fun(nsim, dists[u], param_list[[u]], samples, NULL, "Dunnett")
}
stop_time = Sys.time()
source("sim_fun.R")
library(rankCluster)
start_time = Sys.time()
for(u in 1:length(dists)){
sim_fun(nsim, dists[u], param_list[[u]], samples, NULL, "Dunnett")
}
stop_time = Sys.time()
dur = stop_time - start_time
source("sim_fun.R")
start_time = Sys.time()
for(u in 1:length(dists)){
sim_fun(nsim, dists[u], param_list[[u]], samples, NULL, "Dunnett")
}
stop_time = Sys.time()
source("sim_fun.R")
start_time = Sys.time()
for(u in 1:length(dists)){
sim_fun(nsim, dists[u], param_list[[u]], samples, NULL, "Dunnett")
}
source("sim_fun.R")
start_time = Sys.time()
for(u in 1:length(dists)){
sim_fun(nsim, dists[u], param_list[[u]], samples, NULL, "Dunnett")
}
stop_time = Sys.time()
nsim = 10
dist_c = "norm"
dist_params = list(mean = 0, sd = 1)
param_list[[1]]
param_list[1]
dist_params
dist_params = param_list[1]
samples = samples
f_2 = NULL
c_type = "Dunnett"
cores=detectCores()
cl <- makeCluster(cores-1) #not to overload your computer
registerDoParallel(cl)
results = list()
settings = samples
settings$rho  = 0
settings$dist = dist_c
settings$f_2  = 0
settings$wald = 0
settings$anv  = 0
settings$maxt = 0
z = 3
sets = settings[z,]
sizes = nm_gen(nn = sets$nn, n_i = sets$n_i, m_ij = sets$m_ij, each_s = sets$each_s, both_s = sets$both_s, identical_s = sets$identical_s, identical_c = sets$identical_c)
f2 = sum(sizes[[1]]) - length(sizes[[1]])
c_mat = contrMat(sizes[[1]], type = c_type) %*% diag(1, length(sizes[[1]]))
dec = matrix(0, nrow = 3, ncol = nsim)
theta = rep(1/sets$nn, length(sizes[[1]]))
for(a in 1:nsim){
#dec = foreach(a = 1:nsim, .combine = "cbind", .packages = c("rankCluster")) %do% {
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
#p_hat  = rel_eff(data_n)
#sigma_hat = sigma_est(sizes[[1]], data_n, theta = theta, psi = NULL)
# dec[1,a] = q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[2,a] = q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[3,a] = max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject
c(q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject,
q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject,
max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject)
}
h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
dist_params = param_list[[1]]
h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
#dec = foreach(a = 1:nsim, .combine = "cbind", .packages = c("rankCluster")) %do% {
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
for(a in 1:nsim){
#dec = foreach(a = 1:nsim, .combine = "cbind", .packages = c("rankCluster")) %do% {
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
#p_hat  = rel_eff(data_n)
#sigma_hat = sigma_est(sizes[[1]], data_n, theta = theta, psi = NULL)
# dec[1,a] = q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[2,a] = q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[3,a] = max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject
c(q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject,
q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject,
max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject)
}
setwd("D:/Dropbox/Studium/M.Sc. Statistics/Semester IV/Thesis/Code/MasterThesis")
f2 = sum(sizes[[1]]) - length(sizes[[1]])
c_mat = contrMat(sizes[[1]], type = c_type) %*% diag(1, length(sizes[[1]]))
dec = matrix(0, nrow = 3, ncol = nsim)
theta = rep(1/sets$nn, length(sizes[[1]]))
psi = NULL
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
f_theta_p(c(0.2, 0.4), data_n)
f_theta_p2(c(0.2, 0.4), data_n)
source("util.R")
source("dat_gen.R")
source("stats.R")
source("settings.R")
source("sim_fun.R")
source("utilcpp_wrap.R")
f_theta_p(c(0.2, 0.4), data_n)
f_theta_p2(c(0.2, 0.4), data_n)
A_1 = sigma_est(sizes[[1]], data_n, theta = theta, psi = NULL)
A_2 = sigma_est_p2(nn, data_n, theta = NULL, psi = NULL)
A_2 = sigma_est_p2(sizes[[1]], data_n, theta = NULL, psi = NULL)
A_3 = debug_p(sizes[[1]], data_n, theta = NULL, psi = NULL)
A_1
A_2
A_3
rankCluster::sigma_est(sizes[[1]], data_n)
rankCluster::q_wald(sizes[[1]], data_n, c_mat)
for(a in 1:nsim){
#dec = foreach(a = 1:nsim, .combine = "cbind", .packages = c("rankCluster")) %do% {
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
#p_hat  = rel_eff(data_n)
#sigma_hat = sigma_est(sizes[[1]], data_n, theta = theta, psi = NULL)
# dec[1,a] = q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[2,a] = q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[3,a] = max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject
c(rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject,
rankCluster::q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject,
rankCluster::max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject)
}
a = 1
#dec = foreach(a = 1:nsim, .combine = "cbind", .packages = c("rankCluster")) %do% {
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject
rankCluster::q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject
rankCluster::max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject
theta
psi
rankCluster::sigma_est(sizes[[1]], data_n, theta = theta)
rankCluster::sigma_est(sizes[[1]], data_n, theta = NULL)
rankCluster::max_T(sizes[[1]], data_n, cont = c_mat, alpha = 0.05)
for(a in 1:nsim){
#dec = foreach(a = 1:nsim, .combine = "cbind", .packages = c("rankCluster")) %do% {
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
#p_hat  = rel_eff(data_n)
#sigma_hat = sigma_est(sizes[[1]], data_n, theta = theta, psi = NULL)
# dec[1,a] = q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[2,a] = q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[3,a] = max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject
c(rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject,
rankCluster::q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject,
rankCluster::max_T(sizes[[1]], data_n, p_null = 0.5, c_mat, normal = F, 0.05, theta = theta, psi = NULL)$reject)
}
dec
stopCluster("cl")
stopCluster(cl)
cores=detectCores()
cl <- makeCluster(cores-1) #not to overload your computer
registerDoParallel(cl)
dec = foreach(a = 1:nsim, .combine = "cbind", .packages = c("rankCluster")) %do% {
data_n = h_0_f(sizes[[1]], sizes[[2]], dist = dist_c, corstruct = "independent", rho = settings$rho[z], params = dist_params)
#p_hat  = rel_eff(data_n)
#sigma_hat = sigma_est(sizes[[1]], data_n, theta = theta, psi = NULL)
# dec[1,a] = q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[2,a] = q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject
# dec[3,a] = max_T(data_n, p_null = 0.5, c_mat, sizes[[1]], normal = F, 0.05, theta = theta, psi = NULL)$reject
c(rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta = theta, psi = NULL, alpha = 0.05)$reject,
rankCluster::q_anova(sizes[[1]], data_n, c_mat, f2, theta = theta, psi = NULL, alpha = 0.05)$reject,
rankCluster::max_T(sizes[[1]], data_n, p_null = 0.5, c_mat, normal = F, 0.05, theta = theta, psi = NULL)$reject)
}
st = Sys.time()
abd = foreach(i = 1:100, .combine = "c", .packages = "rankCluster") %dopar% {
rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta, NULL, 0.05)$reject
}
dur1 = Sys.time() - st
abd2 = numeric(100)
st = Sys.time()
for(i in 1:100){
abd2[i] = rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta, NULL, 0.05)$reject
}
dur2 = Sys.time() - st
dur1
dur2
st = Sys.time()
abd = foreach(i = 1:1000, .combine = "c", .packages = "rankCluster") %dopar% {
rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta, NULL, 0.05)$reject
}
dur1 = Sys.time() - st
abd2 = numeric(1000)
st = Sys.time()
for(i in 1:1000){
abd2[i] = rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta, NULL, 0.05)$reject
}
dur2 = Sys.time() - st
dur1
dur2
stopCluster(cl)
cores=detectCores()
cl <- makeCluster(cores-1) #not to overload your computer
registerDoParallel(cl)
st = Sys.time()
abd = foreach(i = 1:10000, .combine = "c", .packages = "rankCluster") %dopar% {
rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta, NULL, 0.05)$reject
}
dur1 = Sys.time() - st
abd2 = numeric(10000)
st = Sys.time()
for(i in 1:10000){
abd2[i] = rankCluster::q_wald(sizes[[1]], data_n, c_mat, theta, NULL, 0.05)$reject
}
dur2 = Sys.time() - st
dur1
dur2
rm(list = ls())
if(!("MASS" %in% installed.packages())) install.packages("MASS", dependencies = T)
if(!("mvtnorm" %in% installed.packages())) install.packages("mvtnorm", dependencies = T)
if(!("copula" %in% installed.packages())) install.packages("copula", dependencies = T)
if(!("multcomp" %in% installed.packages())) install.packages("multcomp", dependencies = T)
if(!("Rcpp" %in% installed.packages())) install.packages("Rcpp", dependencies = T)
if(!("RcppArmadillo" %in% installed.packages())) install.packages("RcppArmadillo", dependencies = T)
if(!("doParallel" %in% installed.packages())) install.packages("doParallel", dependencies = T)
if(!("foreach" %in% installed.packages())) install.packages("foreach")
if(!("rankCluster" %in% installed.packages())) devtools::install_github("spruenke/rankCluster")
#source("util.R")
#source("dat_gen.R")
#source("stats.R")
source("settings.R")
source("sim_fun.R")
#source("utilcpp_wrap.R")
# Simulation --------------------------------------------------------------
nsim  = 100 # Number of Simulation Runs
dists = c("norm", "pois", "beta", "binom")
param_list = list(list(mean = 0, sd = 1), list(lambda = 3), list(shape1 = 2, shape2 = 5), list(size = 1, prob = 0.5))
start_time = Sys.time()
for(u in 1:length(dists)){
sim_fun(nsim, dists[u], param_list[[u]], samples, NULL, "Dunnett")
}
stop_time = Sys.time()
dur = stop_time - start_time
dur
161 / 18.22877
8.832192 *3 * 684
8.832192 *3 * 684 / 24
8.832192 *3 * 684 / 24 / 8
18.22877 / 161 * 3 * 684
18.22877 / 161 * 3 * 684 / 24
18.22877 / 161 * 3 * 684 / 24 / 8
18.22877 / 161 * 3 * 684 / 24 * 3 / 24
# number of Samples nn = 3, 5, 10, 25
# Identical Sample Size n_i = 3, 5, 10, 15, 25, 50, 100, 1000
# Identical Cluster Size m_ij = 3, 5, 10, 15, 20, 25, 40
# One Large, One Small Cluster m_ij = 10, 15, 20, 25; m_ik = 3; m_ih = 40
# One Large, One Small Sample n_i = 10, 15, 25, 50; n_j = 3; n_k = 150
# Identical Cluster Size m_ij = 3, 5, 10, 15, 20, 25, 40
# One Large, One Small Cluster m_ij = 10, 15, 20, 25; m_ik = 3; m_ih = 40
# number of samples
nn = c(3, 5, 10)
each_s = c(F, T)
both_s = c(F, T)
# Identical Sample Sizes --------------------------------------------------
n_i = c(3, 5, 10, 25, 50, 100)
# Identical Cluster Size
m_ij = c(3, 5, 10, 25, 40)
nm_1 = expand.grid(nn, n_i, m_ij)
nm_1$each_s = F
nm_1$both_s = F
nm_1$identical_s = T
nm_1$identical_c = T
nm_1$grp = 1
colnames(nm_1)[1:3] = c("nn", "n_i", "m_ij")
# Large/Small Cluster
m_ij = c(10, 25)
nm_2 = expand.grid(nn, n_i, m_ij, each_s, both_s)
nm_2$identical_s = T
nm_2$identical_c = F
colnames(nm_2)[1:5] = c("nn", "n_i", "m_ij", "each_s", "both_s")
# Remove invalid condition
nm_2 = nm_2[-which(which(nm_2$each_s == T) %in% which(nm_2$both_s == F)),]
nm_2$grp = 2
# Large/Small Sample Size -------------------------------------------------
n_i = c(10, 25, 50)
# Identical Cluster Size
m_ij = c(3, 5, 10, 25, 40)
nm_3 = expand.grid(nn, n_i, m_ij)
nm_3$each_s = F
nm_3$both_s = F
nm_3$identical_s = F
nm_3$identical_c = T
nm_3$grp = 3
colnames(nm_3)[1:3] = c("nn", "n_i", "m_ij")
# Large/Small Cluster
m_ij = c(10, 25)
nm_4 = expand.grid(nn, n_i, m_ij, each_s, both_s)
nm_4$identical_s = F
nm_4$identical_c = F
colnames(nm_4)[1:5] = c("nn", "n_i", "m_ij", "each_s", "both_s")
nm_4 = nm_4[-which(which(nm_4$each_s == T) %in% which(nm_4$both_s == F)),]
nm_4$grp = 4
# Bind --------------------------------------------------------------------
samples = rbind(nm_1, nm_2, nm_3, nm_4)
rm(nm_1, nm_2, nm_3, nm_4, both_s, each_s, m_ij, n_i, nn)
# number of Samples nn = 3, 5, 10, 25
# Identical Sample Size n_i = 3, 5, 10, 15, 25, 50, 100, 1000
# Identical Cluster Size m_ij = 3, 5, 10, 15, 20, 25, 40
# One Large, One Small Cluster m_ij = 10, 15, 20, 25; m_ik = 3; m_ih = 40
# One Large, One Small Sample n_i = 10, 15, 25, 50; n_j = 3; n_k = 150
# Identical Cluster Size m_ij = 3, 5, 10, 15, 20, 25, 40
# One Large, One Small Cluster m_ij = 10, 15, 20, 25; m_ik = 3; m_ih = 40
# number of samples
nn = c(3, 5, 10)
each_s = c(F, T)
both_s = c(F, T)
# Identical Sample Sizes --------------------------------------------------
n_i = c(3, 10, 25, 50, 100)
# Identical Cluster Size
m_ij = c(3, 5, 10, 25, 40)
nm_1 = expand.grid(nn, n_i, m_ij)
nm_1$each_s = F
nm_1$both_s = F
nm_1$identical_s = T
nm_1$identical_c = T
nm_1$grp = 1
colnames(nm_1)[1:3] = c("nn", "n_i", "m_ij")
# Large/Small Cluster
m_ij = c(10, 25)
nm_2 = expand.grid(nn, n_i, m_ij, each_s, both_s)
nm_2$identical_s = T
nm_2$identical_c = F
colnames(nm_2)[1:5] = c("nn", "n_i", "m_ij", "each_s", "both_s")
# Remove invalid condition
nm_2 = nm_2[-which(which(nm_2$each_s == T) %in% which(nm_2$both_s == F)),]
nm_2$grp = 2
# Large/Small Sample Size -------------------------------------------------
n_i = c(10, 25, 50)
# Identical Cluster Size
m_ij = c(3, 5, 10, 25, 40)
nm_3 = expand.grid(nn, n_i, m_ij)
nm_3$each_s = F
nm_3$both_s = F
nm_3$identical_s = F
nm_3$identical_c = T
nm_3$grp = 3
colnames(nm_3)[1:3] = c("nn", "n_i", "m_ij")
# Large/Small Cluster
m_ij = c(10, 25)
nm_4 = expand.grid(nn, n_i, m_ij, each_s, both_s)
nm_4$identical_s = F
nm_4$identical_c = F
colnames(nm_4)[1:5] = c("nn", "n_i", "m_ij", "each_s", "both_s")
nm_4 = nm_4[-which(which(nm_4$each_s == T) %in% which(nm_4$both_s == F)),]
nm_4$grp = 4
# Bind --------------------------------------------------------------------
samples = rbind(nm_1, nm_2, nm_3, nm_4)
rm(nm_1, nm_2, nm_3, nm_4, both_s, each_s, m_ij, n_i, nn)
dur
dur / 161 * 264 * 3 * 4
dur / 161 * 264 * 3 * 4 / 8 / 24
dur / 161 * 3 * 264
dur / 161 * 3 * 264 * 4
dur / 161 * 3 * 264 * 4 / 24
dur / 161 * 3 * 264 * 4 / 8
